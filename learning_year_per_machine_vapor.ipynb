{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# D:\\Toppan\\jupyter\\per machine\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import glob\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "in_dir = 'D:\\\\Toppan\\\\2017-11-20 全データ\\\\処理済(機械ごと)\\\\vapor\\\\with_voc_vectorized'\n",
    "base_out_dir = 'D:\\\\Toppan\\\\2017-11-20 全データ\\\\解析結果(機械ごと)\\\\年間モデル_追加学習なし_特徴量カット'\n",
    "\n",
    "# train and test months\n",
    "month = [ '16年11月', '16年12月', '17年1月', '17年2月', '17年3月', '17年4月',\n",
    "         '17年5月', '17年6月', '17年7月', '17年8月', '17年9月', '17年10月', \n",
    "         '17年11月', '17年12月', '18年1月', '18年2月']\n",
    "\n",
    "month_file = [f for f in os.listdir(in_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holiday_path = 'D:\\\\Toppan\\\\2017-11-20 全データ\\\\データ\\\\切り離し全休日\\\\全休日.xlsx'\n",
    "\n",
    "def mask_out(X, y, month):\n",
    "    \n",
    "    try:\n",
    "        df_filter = pd.read_excel(holiday_path, sheet_name=month, index_col=0).iloc[2:]\n",
    "        seisan = True if '生産\\n有無' in df_filter else False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e, month)\n",
    "        return X, y\n",
    "    \n",
    "    def isBusy(idx):\n",
    "        row = df_filter.loc[idx]\n",
    "\n",
    "        if row.loc['切離\\n有無'] == '切離' or row.loc['全休\\n判定'] == '全休' \\\n",
    "            or row.loc['異常判定'] == '※異常稼動' or row.loc['異常判定'] == '※データ異常' \\\n",
    "            or (seisan and row.loc['生産\\n有無'] == '無'):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    x_busy_idx = []\n",
    "    y_busy_idx = []\n",
    "    for x_idx, y_idx in zip (X.index, y.index):\n",
    "        if isBusy(x_idx) and isBusy(y_idx):\n",
    "            x_busy_idx.append(x_idx)\n",
    "            y_busy_idx.append(y_idx)\n",
    "\n",
    "    return X.loc[x_busy_idx], y.loc[y_busy_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_importance_figure(model, name, features):\n",
    "    \n",
    "    indices = np.argsort(model.feature_importances_)[::-1]\n",
    "    \n",
    "    # save csv\n",
    "    s = pd.Series(data=model.feature_importances_[indices], \n",
    "              index=features[indices])\n",
    "    s.to_csv(os.path.join(out_dir, name + '_寄与度.csv'), encoding='shift-jis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_day_night(acc_abs):\n",
    "    acc_abs_days, acc_abs_nights = [], []\n",
    "    for i, acc in acc_abs.iteritems():\n",
    "        if 7 < i.hour < 22:\n",
    "            acc_abs_days.append(acc)\n",
    "        else:\n",
    "            acc_abs_nights.append(acc)\n",
    "\n",
    "    return acc_abs_days, acc_abs_nights\n",
    "\n",
    "def get_output(res, output, sname, month):\n",
    "    res = res[res['target'] != 0]\n",
    "    \n",
    "    if len(res) == 0:\n",
    "        return None\n",
    "    \n",
    "    y_pred, y_true = res['preds'], res['target']\n",
    "    '''calculate abs accuracy'''\n",
    "    acc_abs = abs(y_pred - y_true) / y_true\n",
    "    '''aplit days and nights'''\n",
    "    acc_abs_days, acc_abs_nights = split_day_night(acc_abs)\n",
    "    len_days, len_nights = len(acc_abs_days), len(acc_abs_nights)\n",
    "\n",
    "    #sname2acc = {'蒸気': [0.2, 0.15], '電力': [0.09, 0.15], '冷水': [0.15, 0.1]}\n",
    "\n",
    "    '''acc stats'''\n",
    "    #len_acc_days = len(list(filter(lambda x: x <= sname2acc[sname][0], acc_abs_days)))\n",
    "    #len_acc_nights = len(list(filter(lambda x: x <= sname2acc[sname][0], acc_abs_nights)))\n",
    "    len_acc_days = len(list(filter(lambda x: x <= 0.2, acc_abs_days)))\n",
    "    len_acc_nights = len(list(filter(lambda x: x <= 0.15, acc_abs_nights)))\n",
    "    acc_stats_days = len_acc_days / len_days\n",
    "    acc_stats_nights = len_acc_nights / len_nights\n",
    "\n",
    "    output['設備名'].append(month + '_' + sname)\n",
    "    output['平日昼・総'].append(len_days)\n",
    "    output['平日夜・総'].append(len_nights)\n",
    "    output['平日昼・基準内'].append(len_acc_days)\n",
    "    output['平日夜・基準内'].append(len_acc_nights)\n",
    "    output['平日昼基準率'].append(acc_stats_days)\n",
    "    output['平日夜基準率'].append(acc_stats_nights)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 年間データを Leave-One-Out で学習・予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16年11月 201611010800_vapor_per_machine.xlsx\n",
      "  train files:  ['201612010800_vapor_per_machine.xlsx', '201701010800_vapor_per_machine.xlsx', '201702010800_vapor_per_machine.xlsx', '201703010800_vapor_per_machine.xlsx', '201704010800_vapor_per_machine.xlsx', '201705010800_vapor_per_machine.xlsx', '201706010800_vapor_per_machine.xlsx', '201707010800_vapor_per_machine.xlsx', '201708010800_vapor_per_machine.xlsx', '201709010800_vapor_per_machine.xlsx', '201710010800_vapor_per_machine.xlsx', '201711010800_vapor_per_machine.xlsx', '201712010800_vapor_per_machine.xlsx', '201801010800_vapor_per_machine.xlsx', '201802010800_vapor_per_machine.xlsx', 'old']\n",
      "  test file:  201611010800_vapor_per_machine.xlsx\n",
      "    now processing:  GDNA\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GDNA learn elapsed time:  294.7741320133209 s\n",
      "16年11月 GDNA None\n",
      "    now processing:  GDNB\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GDNB learn elapsed time:  248.31488633155823 s\n",
      "16年11月 GDNB {'設備名': ['16年11月_GDNB'], '平日昼・総': [280], '平日夜・総': [200], '平日昼・基準内': [181], '平日夜・基準内': [106], '平日昼基準率': [0.6464285714285715], '平日夜基準率': [0.53]}\n",
      "    now processing:  GE07\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GE07 learn elapsed time:  266.99346137046814 s\n",
      "16年11月 GE07 {'設備名': ['16年11月_GE07'], '平日昼・総': [286], '平日夜・総': [185], '平日昼・基準内': [181], '平日夜・基準内': [101], '平日昼基準率': [0.6328671328671329], '平日夜基準率': [0.5459459459459459]}\n",
      "    now processing:  GE51\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GE51 learn elapsed time:  250.08664917945862 s\n",
      "16年11月 GE51 {'設備名': ['16年11月_GE51'], '平日昼・総': [260], '平日夜・総': [209], '平日昼・基準内': [176], '平日夜・基準内': [130], '平日昼基準率': [0.676923076923077], '平日夜基準率': [0.6220095693779905]}\n",
      "    now processing:  GE52\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GE52 learn elapsed time:  301.55314350128174 s\n",
      "16年11月 GE52 {'設備名': ['16年11月_GE52'], '平日昼・総': [141], '平日夜・総': [112], '平日昼・基準内': [95], '平日夜・基準内': [63], '平日昼基準率': [0.6737588652482269], '平日夜基準率': [0.5625]}\n",
      "    now processing:  GE53\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GE53 learn elapsed time:  270.57369589805603 s\n",
      "16年11月 GE53 {'設備名': ['16年11月_GE53'], '平日昼・総': [305], '平日夜・総': [195], '平日昼・基準内': [222], '平日夜・基準内': [134], '平日昼基準率': [0.7278688524590164], '平日夜基準率': [0.6871794871794872]}\n",
      "    now processing:  GL15\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GL15 learn elapsed time:  261.32445549964905 s\n",
      "16年11月 GL15 {'設備名': ['16年11月_GL15'], '平日昼・総': [349], '平日夜・総': [244], '平日昼・基準内': [337], '平日夜・基準内': [233], '平日昼基準率': [0.9656160458452722], '平日夜基準率': [0.9549180327868853]}\n",
      "    now processing:  GL51\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GL51 learn elapsed time:  237.4686872959137 s\n",
      "16年11月 GL51 {'設備名': ['16年11月_GL51'], '平日昼・総': [348], '平日夜・総': [250], '平日昼・基準内': [341], '平日夜・基準内': [246], '平日昼基準率': [0.9798850574712644], '平日夜基準率': [0.984]}\n",
      "    now processing:  GL52\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GL52 learn elapsed time:  248.47695064544678 s\n",
      "16年11月 GL52 {'設備名': ['16年11月_GL52'], '平日昼・総': [346], '平日夜・総': [251], '平日昼・基準内': [328], '平日夜・基準内': [235], '平日昼基準率': [0.9479768786127167], '平日夜基準率': [0.9362549800796812]}\n",
      "    now processing:  GP22\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GP22 learn elapsed time:  286.6014816761017 s\n",
      "16年11月 GP22 {'設備名': ['16年11月_GP22'], '平日昼・総': [325], '平日夜・総': [234], '平日昼・基準内': [207], '平日夜・基準内': [128], '平日昼基準率': [0.6369230769230769], '平日夜基準率': [0.5470085470085471]}\n",
      "    now processing:  GP25\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GP25 learn elapsed time:  282.55349588394165 s\n",
      "16年11月 GP25 {'設備名': ['16年11月_GP25'], '平日昼・総': [300], '平日夜・総': [223], '平日昼・基準内': [134], '平日夜・基準内': [93], '平日昼基準率': [0.44666666666666666], '平日夜基準率': [0.4170403587443946]}\n",
      "    now processing:  GP26\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GP26 learn elapsed time:  364.0118217468262 s\n",
      "16年11月 GP26 {'設備名': ['16年11月_GP26'], '平日昼・総': [303], '平日夜・総': [216], '平日昼・基準内': [137], '平日夜・基準内': [76], '平日昼基準率': [0.4521452145214521], '平日夜基準率': [0.35185185185185186]}\n",
      "    now processing:  GP27\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GP27 learn elapsed time:  292.85882782936096 s\n",
      "16年11月 GP27 {'設備名': ['16年11月_GP27'], '平日昼・総': [290], '平日夜・総': [210], '平日昼・基準内': [92], '平日夜・基準内': [54], '平日昼基準率': [0.31724137931034485], '平日夜基準率': [0.2571428571428571]}\n",
      "    now processing:  GP28\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GP28 learn elapsed time:  294.63638615608215 s\n",
      "16年11月 GP28 {'設備名': ['16年11月_GP28'], '平日昼・総': [250], '平日夜・総': [196], '平日昼・基準内': [48], '平日夜・基準内': [22], '平日昼基準率': [0.192], '平日夜基準率': [0.11224489795918367]}\n",
      "    now processing:  GP29\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GP29 learn elapsed time:  278.30663442611694 s\n",
      "16年11月 GP29 {'設備名': ['16年11月_GP29'], '平日昼・総': [344], '平日夜・総': [250], '平日昼・基準内': [223], '平日夜・基準内': [105], '平日昼基準率': [0.6482558139534884], '平日夜基準率': [0.42]}\n",
      "    now processing:  GP30\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GP30 learn elapsed time:  281.4343409538269 s\n",
      "16年11月 GP30 {'設備名': ['16年11月_GP30'], '平日昼・総': [331], '平日夜・総': [234], '平日昼・基準内': [134], '平日夜・基準内': [81], '平日昼基準率': [0.40483383685800606], '平日夜基準率': [0.34615384615384615]}\n",
      "    now processing:  GP31\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GP31 learn elapsed time:  341.7691538333893 s\n",
      "16年11月 GP31 {'設備名': ['16年11月_GP31'], '平日昼・総': [327], '平日夜・総': [248], '平日昼・基準内': [183], '平日夜・基準内': [134], '平日昼基準率': [0.5596330275229358], '平日夜基準率': [0.5403225806451613]}\n",
      "    now processing:  GP51\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GP51 learn elapsed time:  281.9814898967743 s\n",
      "16年11月 GP51 {'設備名': ['16年11月_GP51'], '平日昼・総': [338], '平日夜・総': [249], '平日昼・基準内': [237], '平日夜・基準内': [176], '平日昼基準率': [0.7011834319526628], '平日夜基準率': [0.7068273092369478]}\n",
      "    now processing:  GP52\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GP52 learn elapsed time:  304.41673588752747 s\n",
      "16年11月 GP52 {'設備名': ['16年11月_GP52'], '平日昼・総': [301], '平日夜・総': [224], '平日昼・基準内': [122], '平日夜・基準内': [60], '平日昼基準率': [0.4053156146179402], '平日夜基準率': [0.26785714285714285]}\n",
      "    now processing:  GP53\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GP53 learn elapsed time:  327.2338693141937 s\n",
      "16年11月 GP53 {'設備名': ['16年11月_GP53'], '平日昼・総': [315], '平日夜・総': [229], '平日昼・基準内': [90], '平日夜・基準内': [40], '平日昼基準率': [0.2857142857142857], '平日夜基準率': [0.17467248908296942]}\n",
      "    now processing:  GT1A_GT1B\n",
      "      X_learn, Y_leran shapes: (8485, 30) (8485,)\n",
      "      X_test, Y_test shapes: (603, 30) (603,)\n",
      "          number of nan in train and test data:  12 0\n",
      "16年11月 GT1A_GT1B learn elapsed time:  255.87518095970154 s\n",
      "16年11月 GT1A_GT1B {'設備名': ['16年11月_GT1A_GT1B'], '平日昼・総': [349], '平日夜・総': [251], '平日昼・基準内': [281], '平日夜・基準内': [187], '平日昼基準率': [0.8051575931232091], '平日夜基準率': [0.7450199203187251]}\n",
      "    now processing:  空調\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "labels ['調整-1' '調整-2' '調整-3' '計画停止-1' '計画停止-2' '計画停止-3'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-a984749ff23d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[1;31m# 寄与度が低い特徴量をカット\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munimportant_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             x, y = mask_out(df_train.drop(columns=['target']).iloc[:-1], \n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3744\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['調整-1' '調整-2' '調整-3' '計画停止-1' '計画停止-2' '計画停止-3'] not contained in axis"
     ]
    }
   ],
   "source": [
    "total_acc = []\n",
    "\n",
    "unimportant_features = ['調整-1', '調整-2', '調整-3', \n",
    "                        '計画停止-1', '計画停止-2', '計画停止-3']\n",
    "\n",
    "for m, f in zip(month, month_file):\n",
    "    \n",
    "    print(m, f)\n",
    "    \n",
    "    # create output dir\n",
    "    out_dir = os.path.join(base_out_dir, m)\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    # set train and test files\n",
    "    test_month, test_month_file = m, f\n",
    "    train_month, train_month_file = [x for x in month if x != m], \\\n",
    "                                            [x for x in month_file if x != f]\n",
    "    \n",
    "    print('  train files: ', train_month_file)\n",
    "    print('  test file: ', test_month_file)\n",
    "    \n",
    "    exl_test = pd.ExcelFile(os.path.join(in_dir, f))\n",
    "    for energy in exl_test.sheet_names:\n",
    "        \n",
    "        print('    now processing: ', energy)\n",
    "        \n",
    "        # learning files\n",
    "        X_learn, Y_learn = [], []\n",
    "        for f, m in zip(train_month_file, train_month):\n",
    "            \n",
    "            df_train = pd.read_excel(os.path.join(in_dir, f), \n",
    "                          sheet_name=energy, \n",
    "                          index_col=0, \n",
    "                          parse_dates=True, \n",
    "                          encoding='shift-jis')\n",
    "            \n",
    "            # 寄与度が低い特徴量をカット\n",
    "            df_train.drop(columns=unimportant_features, inplace=True)\n",
    "            \n",
    "            x, y = mask_out(df_train.drop(columns=['target']).iloc[:-1], \n",
    "                            df_train['target'].iloc[1:], m)\n",
    "\n",
    "            X_learn.append(x)\n",
    "            Y_learn.append(y)\n",
    "\n",
    "        X_learn, Y_learn = pd.concat(X_learn), pd.concat(Y_learn)\n",
    "        print('      X_learn, Y_leran shapes:', X_learn.shape, Y_learn.shape)\n",
    "        \n",
    "        # test file\n",
    "        df_test = exl_test.parse(sheet_name=energy, \n",
    "                            index_col=0, \n",
    "                            parse_dates=True, \n",
    "                            encoding='shift-jis')\n",
    "        \n",
    "        # 寄与度が低い特徴量をカット\n",
    "        df_test.drop(columns=unimportant_features, inplace=True)\n",
    "        \n",
    "        X_test, Y_test = mask_out(df_test.drop(columns=['target']).iloc[:-1], \n",
    "                                  df_test['target'].iloc[1:], test_month)\n",
    "        print('      X_test, Y_test shapes:', X_test.shape, Y_test.shape)\n",
    "        \n",
    "        # fill out nan\n",
    "        X_learn_nan = pd.isnull(X_learn).any(1).nonzero()[0]\n",
    "        X_test_nan = pd.isnull(X_test).any(1).nonzero()[0]\n",
    "        print('          number of nan in train and test data: ', \n",
    "              len(X_learn_nan), len(X_test_nan))\n",
    "        \n",
    "        X_learn, Y_learn = X_learn.fillna(0), Y_learn.fillna(0)\n",
    "        X_test, Y_test = X_test.fillna(0), Y_test.fillna(0)\n",
    "        \n",
    "        # model\n",
    "        model = ExtraTreesRegressor(n_estimators=700, \n",
    "                                      n_jobs=-1, \n",
    "                                      max_depth=11, \n",
    "                                      max_features='auto', \n",
    "                                      criterion='mae', \n",
    "                                      random_state=700, \n",
    "                                      warm_start=True)\n",
    "        \n",
    "        # learn 1 hour later target\n",
    "        start = time.time()\n",
    "        model.fit(X_learn, Y_learn)\n",
    "        elapsed_time = time.time() - start\n",
    "\n",
    "        print(test_month, energy, 'learn elapsed time: ', elapsed_time, 's')\n",
    "\n",
    "        # feature importance\n",
    "        get_importance_figure(model, energy, X_test.columns)\n",
    "        \n",
    "        # test with online learning\n",
    "        preds = []\n",
    "        for idx, row in X_test.iterrows():\n",
    "\n",
    "            # predict\n",
    "            preds.append(model.predict(row.values.reshape(1, -1))[0])\n",
    "\n",
    "            # online learning\n",
    "            '''\n",
    "            model.n_estimators += 50\n",
    "\n",
    "            X_learn = X_learn.append(row)\n",
    "            Y_learn = Y_learn.append(pd.Series(data=Y_test.loc[idx + timedelta(hours=1)], \n",
    "                      index=[idx + timedelta(hours=1)]))\n",
    "\n",
    "            model.fit(X_learn, Y_learn)\n",
    "            '''\n",
    "\n",
    "        # save preds and test\n",
    "        preds = pd.Series(data=preds, index=Y_test.index, name='preds')\n",
    "        result = pd.concat([preds, Y_test], axis=1)\n",
    "        result.to_csv(os.path.join(out_dir, energy + '.csv'), encoding='shift-jis')\n",
    "\n",
    "        # accuracy\n",
    "        output = {'設備名': [], \n",
    "                  '平日昼・総': [], '平日夜・総': [], \n",
    "                  '平日昼・基準内': [], '平日夜・基準内': [], \n",
    "                  '平日昼基準率': [], '平日夜基準率': []}\n",
    "        \n",
    "        output = get_output(result, output, energy, test_month)\n",
    "        \n",
    "        print(test_month, energy, output)\n",
    "\n",
    "        # save accuracy\n",
    "        if output:\n",
    "            accs = pd.DataFrame(output)\n",
    "            accs.to_csv(os.path.join(out_dir, energy + '_acc.csv'), index=False, encoding='shift-jis')\n",
    "            total_acc.append(accs)\n",
    "\n",
    "total_acc = pd.concat(total_acc)\n",
    "total_acc.to_csv(os.path.join(base_out_dir, 'total_acc.csv'), index=False, encoding='shift-jis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "any(X_learn.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "any(Y_learn.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_learn.to_csv(os.path.join(out_dir, 'x_learn.csv'), encoding='shift-jis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_learn=X_learn.fillna(0)\n",
    "pd.isnull(X_learn).any(1).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
