{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# D:\\Toppan\\jupyter\\per machine\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import glob\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "in_dir = 'D:\\\\Toppan\\\\2017-11-20 全データ\\\\処理済(機械ごと)\\\\elec\\\\with_voc_vectorized'\n",
    "base_out_dir = 'D:\\\\Toppan\\\\2017-11-20 全データ\\\\解析結果(機械ごと)\\\\elec\\\\年間モデル_追加学習なし'\n",
    "\n",
    "# train and test months\n",
    "month = [ '16年11月', '16年12月', '17年1月', '17年2月', '17年3月', '17年4月',\n",
    "         '17年5月', '17年6月', '17年7月', '17年8月', '17年9月', '17年10月', \n",
    "         '17年11月', '17年12月', '18年1月', '18年2月']\n",
    "\n",
    "month_file = [f for f in os.listdir(in_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holiday_path = 'D:\\\\Toppan\\\\2017-11-20 全データ\\\\データ\\\\切り離し全休日\\\\全休日.xlsx'\n",
    "\n",
    "def mask_out(X, y, month):\n",
    "    \n",
    "    try:\n",
    "        df_filter = pd.read_excel(holiday_path, sheet_name=month, index_col=0).iloc[2:]\n",
    "        seisan = True if '生産\\n有無' in df_filter else False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e, month)\n",
    "        return X, y\n",
    "    \n",
    "    def isBusy(idx):\n",
    "        row = df_filter.loc[idx]\n",
    "\n",
    "        if row.loc['切離\\n有無'] == '切離' or row.loc['全休\\n判定'] == '全休' \\\n",
    "            or row.loc['異常判定'] == '※異常稼動' or row.loc['異常判定'] == '※データ異常' \\\n",
    "            or (seisan and row.loc['生産\\n有無'] == '無'):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    x_busy_idx = []\n",
    "    y_busy_idx = []\n",
    "    for x_idx, y_idx in zip (X.index, y.index):\n",
    "        if isBusy(x_idx) and isBusy(y_idx):\n",
    "            x_busy_idx.append(x_idx)\n",
    "            y_busy_idx.append(y_idx)\n",
    "\n",
    "    return X.loc[x_busy_idx], y.loc[y_busy_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_importance_figure(model, name, features):\n",
    "    \n",
    "    indices = np.argsort(model.feature_importances_)[::-1]\n",
    "    \n",
    "    # save csv\n",
    "    s = pd.Series(data=model.feature_importances_[indices], \n",
    "              index=features[indices])\n",
    "    s.to_csv(os.path.join(out_dir, name + '_寄与度.csv'), encoding='shift-jis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_day_night(acc_abs):\n",
    "    acc_abs_days, acc_abs_nights = [], []\n",
    "    for i, acc in acc_abs.iteritems():\n",
    "        if 7 < i.hour < 22:\n",
    "            acc_abs_days.append(acc)\n",
    "        else:\n",
    "            acc_abs_nights.append(acc)\n",
    "\n",
    "    return acc_abs_days, acc_abs_nights\n",
    "\n",
    "def get_output(res, output, sname, month):\n",
    "    res = res[res['target'] != 0]\n",
    "    \n",
    "    if len(res) == 0:\n",
    "        return None\n",
    "    \n",
    "    y_pred, y_true = res['preds'], res['target']\n",
    "    '''calculate abs accuracy'''\n",
    "    acc_abs = abs(y_pred - y_true) / y_true\n",
    "    '''aplit days and nights'''\n",
    "    acc_abs_days, acc_abs_nights = split_day_night(acc_abs)\n",
    "    len_days, len_nights = len(acc_abs_days), len(acc_abs_nights)\n",
    "\n",
    "    #sname2acc = {'蒸気': [0.2, 0.15], '電力': [0.09, 0.15], '冷水': [0.15, 0.1]}\n",
    "\n",
    "    '''acc stats'''\n",
    "    len_acc_days = len(list(filter(lambda x: x <= 0.09, acc_abs_days)))\n",
    "    len_acc_nights = len(list(filter(lambda x: x <= 0.15, acc_abs_nights)))\n",
    "    acc_stats_days = len_acc_days / len_days\n",
    "    acc_stats_nights = len_acc_nights / len_nights\n",
    "\n",
    "    output['設備名'].append(month + '_' + sname)\n",
    "    output['平日昼・総'].append(len_days)\n",
    "    output['平日夜・総'].append(len_nights)\n",
    "    output['平日昼・基準内'].append(len_acc_days)\n",
    "    output['平日夜・基準内'].append(len_acc_nights)\n",
    "    output['平日昼基準率'].append(acc_stats_days)\n",
    "    output['平日夜基準率'].append(acc_stats_nights)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_noise(X, Y, energy_name):\n",
    "    \n",
    "    for idx, row in X.iterrows():\n",
    "        \n",
    "        energy_vals = [row[energy_name + '-1'], \n",
    "         row[energy_name + '-2'], \n",
    "         row[energy_name + '-3']]\n",
    "        \n",
    "        if any([x > 10000 for x in energy_vals]):\n",
    "            \n",
    "            X.drop([idx], inplace=True)\n",
    "            Y.drop([idx + timedelta(hours=1)], inplace=True)\n",
    "            print('noise removed at: ', idx)\n",
    "    \n",
    "    for idx, item in Y.iteritems():\n",
    "        if item > 10000:\n",
    "            X.drop([idx - timedelta(hours=1)], inplace=True)\n",
    "            Y.drop([idx], inplace=True)\n",
    "            \n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 年間データを Leave-One-Out で学習・予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16年11月 201611010800_elec_per_machine.xlsx\n",
      "  train files:  ['201612010800_elec_per_machine.xlsx', '201701010800_elec_per_machine.xlsx', '201702010800_elec_per_machine.xlsx', '201703010800_elec_per_machine.xlsx', '201704010800_elec_per_machine.xlsx', '201705010800_elec_per_machine.xlsx', '201706010800_elec_per_machine.xlsx', '201707010800_elec_per_machine.xlsx', '201708010800_elec_per_machine.xlsx', '201709010800_elec_per_machine.xlsx', '201710010800_elec_per_machine.xlsx', '201711010800_elec_per_machine.xlsx', '201712010800_elec_per_machine.xlsx', '201801010800_elec_per_machine.xlsx', '201802010800_elec_per_machine.xlsx']\n",
      "  test file:  201611010800_elec_per_machine.xlsx\n",
      "    now processing:  GP22\n"
     ]
    }
   ],
   "source": [
    "total_acc = []\n",
    "\n",
    "#unimportant_features = ['調整-1', '調整-2', '調整-3', '計画停止-1', '計画停止-2', '計画停止-3']\n",
    "\n",
    "for m, f in zip(month, month_file):\n",
    "    \n",
    "    print(m, f)\n",
    "    \n",
    "    # create output dir\n",
    "    out_dir = os.path.join(base_out_dir, m)\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    # set train and test files\n",
    "    test_month, test_month_file = m, f\n",
    "    train_month, train_month_file = [x for x in month if x != m], \\\n",
    "                                            [x for x in month_file if x != f]\n",
    "    \n",
    "    print('  train files: ', train_month_file)\n",
    "    print('  test file: ', test_month_file)\n",
    "    \n",
    "    exl_test = pd.ExcelFile(os.path.join(in_dir, f))\n",
    "    for energy in exl_test.sheet_names:\n",
    "        \n",
    "        print('    now processing: ', energy)\n",
    "        \n",
    "        # learning files\n",
    "        X_learn, Y_learn = [], []\n",
    "        for f, m in zip(train_month_file, train_month):\n",
    "            \n",
    "            df_train = pd.read_excel(os.path.join(in_dir, f), \n",
    "                          sheet_name=energy, \n",
    "                          index_col=0, \n",
    "                          parse_dates=True, \n",
    "                          encoding='shift-jis')\n",
    "            \n",
    "            # 寄与度が低い特徴量をカット\n",
    "            #df_train.drop(columns=unimportant_features, inplace=True)\n",
    "            \n",
    "            x, y = mask_out(df_train.drop(columns=['target']).iloc[:-1], \n",
    "                            df_train['target'].iloc[1:], m)\n",
    "\n",
    "            X_learn.append(x)\n",
    "            Y_learn.append(y)\n",
    "\n",
    "        X_learn, Y_learn = pd.concat(X_learn), pd.concat(Y_learn)\n",
    "        print('      X_learn, Y_leran shapes:', X_learn.shape, Y_learn.shape)\n",
    "        \n",
    "        # test file\n",
    "        df_test = exl_test.parse(sheet_name=energy, \n",
    "                            index_col=0, \n",
    "                            parse_dates=True, \n",
    "                            encoding='shift-jis')\n",
    "        \n",
    "        # 寄与度が低い特徴量をカット\n",
    "        #df_test.drop(columns=unimportant_features, inplace=True)\n",
    "        \n",
    "        X_test, Y_test = mask_out(df_test.drop(columns=['target']).iloc[:-1], \n",
    "                                  df_test['target'].iloc[1:], test_month)\n",
    "        print('      X_test, Y_test shapes:', X_test.shape, Y_test.shape)\n",
    "        \n",
    "        # fill out nan\n",
    "        X_learn_nan = pd.isnull(X_learn).any(1).nonzero()[0]\n",
    "        X_test_nan = pd.isnull(X_test).any(1).nonzero()[0]\n",
    "        print('          number of nan in train and test data: ', len(X_learn_nan), len(X_test_nan))\n",
    "        \n",
    "        X_learn, Y_learn = X_learn.fillna(0), Y_learn.fillna(0)\n",
    "        X_test, Y_test = X_test.fillna(0), Y_test.fillna(0)\n",
    "    \n",
    "        # remove noise\n",
    "        remove_noise(X_learn, Y_learn, X_learn.columns[-1][:-2])\n",
    "        remove_noise(X_test, Y_test, X_learn.columns[-1][:-2])\n",
    "        \n",
    "        # model\n",
    "        model = ExtraTreesRegressor(n_estimators=700, \n",
    "                                      n_jobs=-1, \n",
    "                                      max_depth=11, \n",
    "                                      max_features='auto', \n",
    "                                      criterion='mae', \n",
    "                                      random_state=700, \n",
    "                                      warm_start=True)\n",
    "        \n",
    "        # learn 1 hour later target\n",
    "        start = time.time()\n",
    "        model.fit(X_learn, Y_learn)\n",
    "        elapsed_time = time.time() - start\n",
    "\n",
    "        print(test_month, energy, 'learn elapsed time: ', elapsed_time, 's')\n",
    "\n",
    "        # feature importance\n",
    "        get_importance_figure(model, energy, X_test.columns)\n",
    "        \n",
    "        # test with online learning\n",
    "        preds = []\n",
    "        for idx, row in X_test.iterrows():\n",
    "\n",
    "            # predict\n",
    "            preds.append(model.predict(row.values.reshape(1, -1))[0])\n",
    "\n",
    "            # online learning\n",
    "            '''\n",
    "            model.n_estimators += 50\n",
    "\n",
    "            X_learn = X_learn.append(row)\n",
    "            Y_learn = Y_learn.append(pd.Series(data=Y_test.loc[idx + timedelta(hours=1)], \n",
    "                      index=[idx + timedelta(hours=1)]))\n",
    "\n",
    "            model.fit(X_learn, Y_learn)\n",
    "            '''\n",
    "\n",
    "        # save preds and test\n",
    "        preds = pd.Series(data=preds, index=Y_test.index, name='preds')\n",
    "        result = pd.concat([preds, Y_test], axis=1)\n",
    "        result.to_csv(os.path.join(out_dir, energy + '.csv'), encoding='shift-jis')\n",
    "\n",
    "        # accuracy\n",
    "        output = {'設備名': [], \n",
    "                  '平日昼・総': [], '平日夜・総': [], \n",
    "                  '平日昼・基準内': [], '平日夜・基準内': [], \n",
    "                  '平日昼基準率': [], '平日夜基準率': []}\n",
    "        \n",
    "        output = get_output(result, output, energy, test_month)\n",
    "        \n",
    "        print(test_month, energy, output)\n",
    "\n",
    "        # save accuracy\n",
    "        if output:\n",
    "            accs = pd.DataFrame(output)\n",
    "            accs.set_index('設備名')\n",
    "            \n",
    "            accs.to_csv(os.path.join(out_dir, energy + '_acc.csv'), \n",
    "                        index=False, \n",
    "                        encoding='shift-jis')\n",
    "            \n",
    "            total_acc.append(accs)\n",
    "\n",
    "total_acc = pd.concat(total_acc)\n",
    "total_acc.to_csv(os.path.join(base_out_dir, 'total_acc.csv'), \n",
    "                 index=False, \n",
    "                 encoding='shift-jis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
